{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730da8f2",
   "metadata": {},
   "source": [
    "# K Fold cross validation\n",
    "\n",
    "K-fold cross-validation is a valuable technique for model evaluation and helps in obtaining a more accurate and reliable estimate of a model's performance on unseen data.\n",
    "\n",
    "We devide the samples into folds.Say, we have 100 samples then we fold them into 5 folds each containing 20 samples.Then we train the model with last 4 folds and for testing we use first 1 fold and finally notedown the score. \n",
    "\n",
    "Then we use 2nd fold for testing and rest of the folds for training. And repeat the process. Finally we,  average all the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f493a5",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32538d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e76620",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e668779",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e688081c",
   "metadata": {},
   "source": [
    "# Train, Test and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67953a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(digits.data, digits.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f12493",
   "metadata": {},
   "source": [
    "# Using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d99771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Logistic Regression: 96.85185185185186 %\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, solver='sag')\n",
    "lr.fit(X_train, Y_train)\n",
    "print(f\"Accuracy from Logistic Regression: {lr.score(X_test, Y_test)*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef9240",
   "metadata": {},
   "source": [
    "# Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb235644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from SVM: 36.851851851851855 %\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train, Y_train)\n",
    "print(f\"Accuracy from SVM: {svm.score(X_test, Y_test)*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531537e",
   "metadata": {},
   "source": [
    "# Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ad5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Random Forest: 95.74074074074073 %\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf.fit(X_train, Y_train)\n",
    "print(f\"Accuracy from Random Forest: {rf.score(X_test, Y_test)*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a6d36",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "We can after using different different classifiers, it is visible that our model accuracy is not uniform. Depending on the train and test data it is changing all the time. Moreover, we can't say the model accuracy is consistent or which model is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107116b0",
   "metadata": {},
   "source": [
    "# K Fold Validation.\n",
    "\n",
    "### Basic example  using some numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921dae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3) # n_splits means the number of folds('groups')\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0fb9af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6230e7d",
   "metadata": {},
   "source": [
    "kf.split([1,2,3,4,5,6,7,8,9]), here this field returns an iterator.\n",
    "And in each iterations it will return train_index and test_index. As we supplied n_splits = 3, it divides the set into 3 folds. One fold[0,1,2] for testing and two folds[3,4,5,6,7,8] for training.\n",
    "\n",
    "In second iteration, [0,1,2,6,7,8] goes for training and [3,4,5] goes for testing.\n",
    "\n",
    "Repeats.\n",
    "\n",
    "Example ends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f0d04",
   "metadata": {},
   "source": [
    "### Creating a reusable function.\n",
    "\n",
    "which we can use for LogisticRegression, SVM, RandomForestClassifier as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1316d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, Y_train, Y_test):\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22544836",
   "metadata": {},
   "source": [
    "# Using K Fold for digits example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53eebe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f38ef",
   "metadata": {},
   "source": [
    "'StratifiedKFold' is similar to KFold but it is better, Because, when we are spearating our folds it will divide each classification catagories in a uniform way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db496987",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = []\n",
    "scores_lr = []\n",
    "scores_rf = []\n",
    "\n",
    "for train_index, test_index in kf.split(digits.data):\n",
    "    X_train, X_test, Y_train, Y_test = digits.data[train_index], digits.data[test_index], digits.target[train_index], digits.target[test_index]\n",
    "        \n",
    "    scores_lr.append(get_score(LogisticRegression(max_iter=1000, solver='sag'), X_train, X_test, Y_train, Y_test))\n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, Y_train, Y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff9dfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9282136894824707, 0.9432387312186978, 0.9098497495826378]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763e29f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41068447412353926, 0.41569282136894825, 0.4273789649415693]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40922ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9265442404006677, 0.9582637729549248, 0.9181969949916527]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c09f5b4",
   "metadata": {},
   "source": [
    "Insted of using so codes in line[15], we can use 'cross_val_score'.\n",
    "# cross_val_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa358760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1d1d9",
   "metadata": {},
   "source": [
    "### Logistic Regression model performance using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "481da02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91944444, 0.86666667, 0.94428969, 0.93593315, 0.89415042])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(max_iter=1000, solver='sag'), digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843a364",
   "metadata": {},
   "source": [
    "### SVM model performance using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e5a8849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41111111, 0.45      , 0.454039  , 0.44846797, 0.47910864])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(gamma='auto'), digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2d5b0",
   "metadata": {},
   "source": [
    "### Random Forest model performance using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f8ae207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94166667, 0.90555556, 0.93871866, 0.95264624, 0.93314763])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=40), digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe1367",
   "metadata": {},
   "source": [
    "We can see that RandomForestClassifier is working best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda3055",
   "metadata": {},
   "source": [
    "# Checking the performance after tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f777c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8775729360645561"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = cross_val_score(RandomForestClassifier(n_estimators=5),digits.data, digits.target, cv=10)\n",
    "np.average(score1)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b11d35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337647423960271"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = cross_val_score(RandomForestClassifier(n_estimators=20),digits.data, digits.target, cv=10)\n",
    "np.average(score2)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27348621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465859714463066"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score3 = cross_val_score(RandomForestClassifier(n_estimators=40),digits.data, digits.target, cv=10)\n",
    "np.average(score3)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c049903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9510304158907511"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score4 = cross_val_score(RandomForestClassifier(n_estimators=80),digits.data, digits.target, cv=10)\n",
    "np.average(score4)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda13f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
